## Materials, Methods and Results {.page_break_before}

### Sample procurement and preparation

The fish were kept in 75% ethanol for long-term storage at the Swiss Federal Institute of Aquatic Science and Technology (Eawag).
They were delivered to the Institute of Anatomy for micro-CT imaging sorted into batches of approximately equal length.

### Ethics statement

The study used specimens from an already existing fish collection, built over decades of research led by Ole Seehausen and continuing until today.
All relevant permits for research, the permits for export from the respective country and import to Switzerland were given and the research has followed modern ethical guidelines for scientific research.

### Micro-computed tomographic imaging

All samples were scanned on two of the three available high-resolution micro-CT machines of the Institute of Anatomy of the University of Bern in Switzerland, a SkyScan 1272 and a SkyScan 2214 (both Bruker microCT, Kontich, Belgium).

The fish were sorted into 'bins' based on their physical size.
We used a custom-made sample-holder to scan each of the fish in our machines.
It was 3D-printed on a Form 2 desktop stereolithography printer (Formlabs, Somerville, Massachusetts, USA), the file for printing the holder is available online [@https://github.com/TomoGraphics/Hol3Drs/blob/master/STL/EAWAG.Fish.stl] as part of a library of sample holders for tomographic scanning of biomedical samples [@doi:10.5281/zenodo.2587555].
The original *OpenSCAD* [@https://openscad.org] file [@https://github.com/TomoGraphics/Hol3Drs/blob/master/EAWAG.Fish.scad] is parametrized to effortlessly generate a file for 3D-printing sample holders to accommodate the varying width, height and length classes of the fish.

In total, we acquired 362 tomographic scans of 129 different specimens.
All the scanning parameters are collected in a table in the [Supplementary Materials]; a generalized rundown is given below.

Since the fish greatly varied in their length (specimen length varied between 6 cm and 18 cm), the voxel sizes of each of the acquired datasets also varies greatly.
We acquired datasets with (isometric) voxel sizes ranging from 3.5 to 50 μm.
<!---
12  103637  rec   3.499972
182  12319  head_50um_rec  49.998527
--->

Depending on the size of the specimen we set the X-ray source voltage to 50--80 kV and---depending on the voltage---to a current between 107 and 200 μA.
The X-ray spectrum was filtered either by an aluminum filter of varying thickness (either 0.25, 0.5 or 1 mm for increasing specimen size) before digitization to projection images or recorded in an unfiltered way (for smaller specimen).
In total we recorded 9.5 TB of projection images (`TIFF` and `*.iif` files, where the `*.iif` files are for the so-called alignment scans).

All the recorded projection images were subsequently reconstructed into virtual 3D stacks of axial `PNG` images spanning the regions of interest of each fish.
All the specimens were scanned with their mouths facing downward in the sample holder and rotating along their long axis.
We thus manually aligned each of the reconstructed datasets so that the lateral axis of the fish was horizontal in relation to the x and y direction of the reconstructed slices.
We reconstructed the projection images with NRecon (Version 1.7.4.6, Bruker microCT, Kontich, Belgium) with varying ring artifact and beam hardening correction values, depending on each fish (again, all relevant values are listed in the [Supplementary Materials]).
In total, this resulted in 1.4 TB of reconstruction images (nearly one million `*rec*.png` files).
Each of the 362 scans we performed has on average about 2700 reconstruction images.

<!---
print('We have %s reconstructions on %s' % (Data['Number of reconstructions'].sum(), Root))

We have 992724 reconstructions on /home/habi/research-storage-iee

print('This is about %s reconstructions per scan (%s scans, %s fishes)' % (round(Data['Number of reconstructions'].sum() / len(Data)), len(Data), len(Data.Fish.unique())))

This is about 2720 reconstructions per scan (365 scans, 137 folders)
--->

A small script [@https://github.com/habi/EAWAG/blob/master/rsync-fishes.sh] was used to generate redundant (archival) copies of the raw projection images and copy all the files to a shared network drive on the 'Research Storage' infrastructure of the University of Bern, enabling collaboration on the data by all authorized persons at the same time.
This automated archival and copying process made it possible to delete the raw projection images on the production system shortly after acquisition, freeing resources and easing data handling.
A subset of the data, namely the log files and reconstructed image stacks were kept on the production system for working with it (as described in [Preparation for analysis] below).

### Data analysis

We wrote a set of *Jupyter* [@https://eprints.soton.ac.uk/403913] notebooks with *Python* code to work with the images and wrangle the acquired data.
The notebooks were written at the start of the project, to be able to process new scans as soon as they were reconstructed.
Re-runs of the notebook added newly scanned and reconstructed data to the analysis, facilitating an efficient quality check of the scans and batched processing of the data.

All analysis notebooks for this work are available online [@doi:10.5281/zenodo.6798632].

#### Preparation for analysis

The [main *Jupyter* notebook](https://github.com/habi/EAWAG/blob/master/DisplayFishes.ipynb) for this manuscript dealt with reading all log and image files and preparing images for quality checking and further analysis.

At first, *all* log files of *all* the data present in the processed folder were read into a *pandas* [@doi:10.5281/zenodo.7093122; @doi:10.25080/Majora-92bf1922-00a] dataframe.
This already enabled us to extract the specimen name and scan, since we performed multiple scans for each specimen, i.e. a low resolution scan with large field of view for the whole head and one or two scans in high resolution focusing on the region of the oral and pharyngeal jaws.
From the log files we extracted the relevant values for double-checking the necessary parameters of each scan.
All relevant values for each scan were also saved into the dataframe and saved out to the aforementioned table in the [Supplementary Materials] at the end of each run of the notebook.

After performing 'sanity checks' of the data and reconstruction parameters, we used *Dask* [@dask] to efficiently access the tomographic data on disk (in the end amounting to a total of nearly a million single images).
On average, each of the tomographic datasets contains around 2700 slices, so the total size of the acquired data exceeds the RAM size available on an average high-end workstation.

At first, we extracted the central view of each of the three axial directions of the datasets (i.e. 'anteroposterior', 'lateral' and 'dorsoventral' view) and either saved those to disk or loaded them from disk if they were already generated in prior runs of the notebook.
The notebook then also generated the maximum intensity projection (MIP) for each of the anatomical planes and either saved them to disk or loaded them from prior runs.

At the end of the notebook we performed a final sanity check on the MIP images.
In this check we examined the mapping of the gray values of the raw projection images to gray values in the reconstructions, i.e. checked that no overexposed pixels are present in the MIP images.
This is an efficient way for double-checking the gray value mapping, since the MIP images have already been generated in prior steps of the notebook and contain the highest gray values present in all the reconstructed images of each scan.

### Image processing

#### Extraction of oral and pharyngeal jaws, visualization of tomographic data

To extract the oral jaw (OJ) and pharyngeal jaw (PJ) of the fish, we used [*3D Slicer*](https://www.slicer.org) (Version 4.11.20210226) [@doi:10.1016/j.mri.2012.05.001] extended with the *SlicerMorph* tools [@doi:10.1111/2041-210X.13669] which aim to help biologists work with 3D specimen data.
The reconstructed image stacks were loaded into [*ImageStacks*](https://www.slicer.org/wiki/Documentation/Labs/ImageStacks), depending on their size we reduced the image resolution (i.e. downscaled the images) for this first step.
The three-dimensional volume was rendered via [*VTK GPU Ray Casting*](https://slicer.readthedocs.io/en/latest/user_guide/modules/volumerendering.html).
A custom-made volume property was used as an input to view the scans.
Using toggles in the volume rendering, we defined regions of interest (ROIs) for both the OJs and PJs in each specimen.
These ROIs were then extracted in their native resolution from the original dataset for further processing.
Using the gray value thresholding function in *3D Slicer*'s [*Segment Editor*](https://slicer.readthedocs.io/en/latest/user_guide/modules/segmenteditor.html), the teeth in both the oral and pharyngeal jaws were extracted.
We used the *Scissor* and *Island* tools of the *Segment Editor* to isolate single regions.

Processed regions of interest were exported as `Nrrd` [@https://teem.sourceforge.net/nrrd/] files.
The three-dimensional visualizations of all regions of interest for each specimen were compiled into overview images (see Figure @fig:104016 for an example from the compilation document).
In total we compiled overview of 125 specimens with full head morphology, oral jaw and lower pharyngeal jaw profiles.

![Overview of data from sample 104016, *Enterochromis I cinctus*, from 'Station E' in the transect of Mwanza Bay at the southern edge of Lake Victoria.
  A map showing the detailed location of 'Station E' is shown in Fig. 1 of [@doi:10.1007/s10750-016-2925-1].
  Panel A: Three-dimensional visualization of the head scan.
  Panel B: Three-dimensional visualization of the oral jaw scan.
  Panel C: Photograph of the specimen.
  Panels D and E: Three-dimensional visualization of the pharyngeal jaw, dorsoventral and lateral view, respectively.](images/104016.png){#fig:104016}

<!---
- 104016 length is given as '<7 cm' in XLS sheet.
- PJ triangle measured on MIP of 104016_PJ.seg.nrrd, giving 1067.208, 1024.018, 1040.663, i.e. 1045 px. Scanned at 5 um, this gives 5.219815 mm.
 as length in Fiji.
- Cusp distance measured on MIP of 104016_OJcrop.nrrd, giving 41.485, 39.850, 43.932, 48.600, i.e. 45 px. Scanned at 5 um, this gives 217 um.
--->

#### Principal components analysis of skull landmarks

Current studies are using 3D geometric morphometrics to compare the morphological shape of these scanned cichlids using statistical analysis.
We used a homologous landmark scheme across one-half of the skull for higher density of shape information [@doi:10.1643/i2021016; @doi:10.1093/iob/obac022], and landmarks were placed on each specimen using *3D Slicer*.
To examine differences in shape across the species sampled, we performed a Generalized Procrustes Superimposition on the landmark data to remove the effects of location, size, and rotation from the analysis using the *geomorph* package in *R* (Version 4.2.1) with *RStudio* (Version 2022.07.2+576) [@doi:10.1111/2041-210X.13029; @geomorph; @rrpp; @r ;@rstudio].
This process brings all specimens to a common origin, scales the landmarks to a unit centroid size, and rotates specimens to reduce distances between landmarks.
A principal components analysis was then performed in *geomorph* on the superimposed landmark data to visualize the major axes of shape change across sampled species.
We then used phylogenetic information to identify instances of repeated evolution of trophic adaptations in these cichlids.

#### Automatic extraction of otoliths

Otoliths are structures made up of mostly calcium carbonate located in the head of fishes.
Due to their composition, they are easily distinguished in the X-ray images we acquired.
We devised an image processing method to automatically and robustly detect the location of the otoliths in the heads of the cichlids we scanned and to extract them from the original data.
The whole method is implemented in its own [*Jupyter* notebook](https://github.com/habi/EAWAG/blob/master/ExtractOtoliths.ipynb) (part of the aforementioned analysis repository [@doi:10.5281/zenodo.6798632]).

Since we took great care to scan the fish parallel to their anteroposterior direction and reconstructed the tomographic datasets parallel to the lateral and dorsoventral direction of the fish we could use this 'preparation' for automatically extracting the otoliths the tomographic datasets of the whole fish heads.
By extracting both the peaks and the peak widths of the gray values along both the horizontal and vertical direction of the MIP (generated above) we robustly detected the position of the otoliths in the datasets.
The robust detection is supported by suppressing a small, configurable part of each region, i.e. the front and back, top and bottom or the flanks.

![Visualization of automatic otolith extraction.
  The top row shows the found location of the otolith center in each of the three anatomical directions.
  The bottom row shows a maximum intensity projection of each of the three anatomical directions of the extracted otolith region.](images/104016.head.rec.otolither.position.png){#fig:otolithextraction}

Figure @fig:otolithextraction shows the visualization of the process.
The colored horizontal and vertical bars in each of the directional MIPs denote the found peak location of the two appropriate values.
The white bars show the mean of the to detected positions, which was used for extracting the otoliths from the original datasets.
Making use of the *Dask* library facilitated efficient access to all the data on disk and writing out small, cropped copies of the datasets around the otolith positions.

By detecting the largest components in the cropped copies of the datasets we can easily extract and visualize the otoliths in 3D, as shown in Figure @fig:otolith3d.
The extracted otoliths are thus prepared for further analysis and visualization.
The simple three-dimensional visualization is integrated in the aforementioned *Jupyter* notebook through an integrated visualization library [@https://github.com/K3D-tools/K3D-jupyter] and is also shown in the [Supplementary Materials].

![Three-dimensional view of extracted otoliths of specimen 104016.
  The specimen was scanned with an isotropic voxel size of 13 μm.
  The extracted otolith has a size of approximately 250 x 350 x 150 pixels.
  The axes labels correspond to mm.
  A dynamic view of the visualization is available in the [Supplementary Materials].](images/104016.head.rec.otolith.region.3D.png){#fig:otolith3d}

The notebook for extracting the otoliths can be run in your browser without installing any additional software (via *Binder* [@doi:10.25080/majora-4af1f417-011]).
To do this, one starts the notebook by [clicking a single button](https://mybinder.org/v2/gh/habi/eawag/HEAD?labpath=ExtractOtoliths.ipynb) in the [README file](https://github.com/habi/EAWAG/blob/master/README.md) of the [project repository](https://github.com/habi/EAWAG) [@doi:10.5281/zenodo.6798632].
This starts a computing environment in the cloud, downloads the tomographic data we acquired of *one* specimen, and performs both the otolith extraction and visualization in your browser.
